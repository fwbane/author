{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EAP_start = 1827\n",
    "EAP_end = 1849\n",
    "EAP_major_works = [1831, 1839, 1843, 1845, 1846, 1849]\n",
    "HPL_start = 1910\n",
    "HPL_end = 1943\n",
    "HPL_major_works = [1928, 1936, 1943]\n",
    "MWS_start = 1818\n",
    "MWS_end = 1837\n",
    "MWS_major_works = [1818, 1823, 1826, 1830, 1835, 1837]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', index_col='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngram_data_regex = re.compile(r'imeseries\\\": \\[(\\d|\\.|\\s|,|e|-)*\\]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngram_frequency_from_request(request, regex):\n",
    "    results = []\n",
    "    frequencies = regex.search(request.text).group()\n",
    "    frequencies = frequencies[13:-1]\n",
    "    frequencies = frequencies.split(\", \")\n",
    "    frequencies = [float(f) for f in frequencies]\n",
    "    results.append(np.mean([f for f in frequencies[EAP_start-1818:EAP_end-1818] if f>0]))\n",
    "    results.append(np.mean([f for f in frequencies[HPL_start-1818:HPL_end-1818] if f>0]))\n",
    "    results.append(np.mean([f for f in frequencies[MWS_start-1818:MWS_end-1818] if f>0]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_list = []\n",
    "stopWords = set(stopwords.words('english'))\n",
    "for sentence in df.text:\n",
    "    tokens = tokenize.word_tokenize(sentence)\n",
    "    tokens = [t for t in tokens if len(t)>1 and t not in stopWords]\n",
    "    token_list.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon = set()\n",
    "for sentence in token_list:\n",
    "    lexicon.update(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27575"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicons = []\n",
    "for author in ['EAP', 'HPL', 'MWS']:\n",
    "    author_lexicon = set()\n",
    "    for sentence in df[df['author']==author].text:\n",
    "        tokens = tokenize.word_tokenize(sentence)\n",
    "        tokens = [t.lower() for t in tokens if len(t)>1 and t not in stopWords]\n",
    "        author_lexicon.update(tokens)\n",
    "    lexicons.append(author_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EAP_lexicon, HPL_lexicon, MWS_lexicon = lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15443 14495 11536\n"
     ]
    }
   ],
   "source": [
    "print(len(EAP_lexicon), len(HPL_lexicon), len(MWS_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3003"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWS_unique_words = MWS_lexicon.difference(HPL_lexicon.union(EAP_lexicon))\n",
    "len(MWS_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5584"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPL_unique_words = HPL_lexicon.difference(MWS_lexicon.union(EAP_lexicon))\n",
    "len(HPL_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5882"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAP_unique_words = EAP_lexicon.difference(HPL_lexicon.union(MWS_lexicon))\n",
    "len(EAP_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastening 1 6\n",
      "eave 1 344\n",
      "bug 29 26\n",
      "'wery 1 0\n",
      "strived 1 1\n",
      "fairies 2 1\n",
      "doux 2 2\n",
      "saucer 1 2\n",
      "perseveringly 2 2\n",
      "editors 2 8\n",
      "predicate 1 1\n",
      "esquimau 1 0\n",
      "cimabué 1 0\n",
      "chateaubriand 1 0\n",
      "stables 6 7\n",
      "sacks 1 1\n",
      "morto 1 2\n",
      "riper 1 1\n",
      "assumes 2 2\n",
      "waker 9 9\n"
     ]
    }
   ],
   "source": [
    "# POP method is destructive - removes and returns the items from the set. Re-run above three cells after experimentation\n",
    "for i in range(20):\n",
    "    word = EAP_unique_words.pop()\n",
    "    print(word, wordcounts[word], sum([word in text for text in df.text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lexicon_frequencies(lexicon):\n",
    "    lexicon_frequencies = []\n",
    "    error_counter = 0\n",
    "    sleep_time = 1\n",
    "    BASEURL = \"https://books.google.com/ngrams/graph?content={}&year_start=1818&year_end=1943&corpus=16&smoothing=0\"\n",
    "    for n, word in enumerate(lexicon):\n",
    "        if n%1378 == 1:\n",
    "            print(\"{}% done!\".format(round(len(lexicon)/n), 2))\n",
    "        if error_counter > 8:\n",
    "            print(\"too many errors. Sleep time = {}\".format(sleep_time))\n",
    "            break\n",
    "        request = requests.get(BASEURL.format(word))\n",
    "        if request.status_code != 200:\n",
    "            error_counter += 1\n",
    "            time.sleep(sleep_time)\n",
    "            request = requests.get(BASEURL.format(word))\n",
    "            if request.status_code != 200:\n",
    "                error_counter += 1\n",
    "                print(\"two consecutive errors\")\n",
    "                print(request.status_code, request.text)\n",
    "                time.sleep(300)\n",
    "                sleep_time *= 2\n",
    "        ngram_frequencies = get_ngram_frequency_from_request(request, ngram_data_regex)\n",
    "        lexicon_frequencies.append((word, ngram_frequencies))\n",
    "        time.sleep(sleep_time)\n",
    "    return lexicon_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexicon_frequencies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-902631fc68df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlexicon_frequencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lexicon_frequencies' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1818"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(min(EAP_major_works), min(MWS_major_works), min(HPL_major_works))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1943"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(EAP_major_works), max(MWS_major_works), max(HPL_major_works))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors = ['EAP', 'HPL', 'MWS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of sentences by EAP: 142.22594936708862\n",
      "Average length of sentences by HPL: 155.84347826086957\n",
      "Average length of sentences by MWS: 151.65982792852415\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Average length of sentences by {}: {}\".format(author, np.mean([len(t) for t in df[df['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings by EAP: 7900\n",
      "Number of words by EAP: 200995\n",
      "Average words per string: 25.44240506329114\n",
      "Number of strings by HPL: 5635\n",
      "Number of words by HPL: 156651\n",
      "Average words per string: 27.799645075421473\n",
      "Number of strings by MWS: 6044\n",
      "Number of words by MWS: 165710\n",
      "Average words per string: 27.417273328921244\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings by {}: {}\".format(author, df[df['author']==author].shape[0]))\n",
    "    print(\"Number of words by {}: {}\".format(author, sum([len(t.split(\" \")) for t in df[df['author']==author].text])))\n",
    "    print(\"Average words per string: {}\".format((sum([len(t.split(\" \")) for t in df[df['author']==author].text]))/df[df['author']==author].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EAP_strings, MWS_strings, HPL_strings = 7900, 6044, 5635\n",
    "EAP_words, MWS_words, HPL_words = 200995, 165710, 156651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string_ratios = np.asarray([EAP_strings, HPL_strings, MWS_strings])/(EAP_strings + HPL_strings + MWS_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40349354, 0.28780837, 0.30869809])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_ratios = np.asarray([EAP_words, HPL_words, MWS_words])/(EAP_words + HPL_words + MWS_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38405024, 0.29932016, 0.3166296 ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EAP_sentence_lengths = [len(t) for t in df[df['author']=='EAP'].text]\n",
    "HPL_sentence_lengths = [len(t) for t in df[df['author']=='HPL'].text]\n",
    "MWS_sentence_lengths = [len(t) for t in df[df['author']=='MWS'].text]\n",
    "labels = ['EAP', 'HPL', 'MWS']\n",
    "\n",
    "plt.figure()\n",
    "H = plt.hist([EAP_sentence_lengths, HPL_sentence_lengths, MWS_sentence_lengths], label=labels, bins=[i for i in range(0, 400, 30)])\n",
    "leg = plt.legend(frameon=False)\n",
    "plt.title(\"Sentence lengths of the three authors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EAP_word_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-053336897877>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEAP_word_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHPL_word_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMWS_word_counts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mleg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Words per sentence of the three authors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EAP_word_counts' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "H = plt.hist([EAP_word_counts, HPL_word_counts, MWS_word_counts], label=labels, bins=[i for i in range(0, 60, 3)])\n",
    "leg = plt.legend(frameon=False)\n",
    "plt.title(\"Words per sentence of the three authors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    uppers = 0\n",
    "    total = 0\n",
    "    for t in df[df['author']==author].text:\n",
    "        total += len(t)\n",
    "        uppers += sum([l.isupper() for l in t])\n",
    "    print(\"Number of capital letters by {}: {}\\tRatio: {}\"\n",
    "          .format(author, uppers, uppers/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    print(\"Average characters per word by {}: {}\"\n",
    "          .format(author, (sum([len(t) for t in df[df['author']==author].text])/\n",
    "                           (sum([len(t.split(\" \")) for t in df[df['author']==author].text])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing the word 'l'' by EAP: 165\n",
      "Number of strings containing the word 'l'' by HPL: 46\n",
      "Number of strings containing the word 'l'' by MWS: 306\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing the word 'l\\'' by {}: {}\".format(author, sum([':' in t for t in df2[df2['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['á']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = re.compile(r'[à|â|æ|ç|è|ë|ê|ï|î|ô|œ|ÿ|û|ù|á|é|í|ó|ú|ü]')\n",
    "chars.findall(\"flimflám\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing accented characters by EAP: 116\n",
      "Number of strings containing accented characters by HPL: 52\n",
      "Number of strings containing accented characters by MWS: 0\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing accented characters by {}: {}\".format(author, sum([1 for c in [chars.search(t.lower()) for t in df[df['author']==author].text] if c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for c in [chars.findall(t) for t in df2[df2['author']=='EAP'].text] if c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing the word 'whence' by EAP: 9\n",
      "Number of strings containing the word 'whence' by HPL: 10\n",
      "Number of strings containing the word 'whence' by MWS: 8\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing the word 'whence' by {}: {}\".format(author, sum(['whence' in t.lower() for t in df[df['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing ! by EAP: 0\n",
      "Number of strings containing ! by HPL: 0\n",
      "Number of strings containing ! by MWS: 0\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing ! by {}: {}\".format(author, sum(['\\!' in t for t in df[df['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing L' or l' by EAP: 83\n",
      "Number of strings containing L' or l' by HPL: 22\n",
      "Number of strings containing L' or l' by MWS: 19\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing L' or l' by {}: {}\".format(author, sum(['l\\''  in t.lower() for t in df[df['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing a semicolon by EAP: 1084\n",
      "Number of strings containing a semicolon by HPL: 1084\n",
      "Number of strings containing a semicolon by MWS: 1969\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing a semicolon by {}: {}\".format(author, sum([';'  in t.lower() for t in df[df['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing quotation marks by EAP: 1326\n",
      "Number of strings containing quotation marks by HPL: 313\n",
      "Number of strings containing quotation marks by MWS: 788\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing quotation marks by {}: {}\".format(author, sum(['\\\"' in t for t in df[df['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing 'ae' by EAP: 67\n",
      "Number of strings containing 'ae' by HPL: 118\n",
      "Number of strings containing 'ae' by MWS: 33\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing 'ae' by {}: {}\".format(author, sum(['ae' in t for t in df[df['author']==author].text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings containing 'æ' by EAP: 32\n",
      "Number of strings containing 'æ' by HPL: 9\n",
      "Number of strings containing 'æ' by MWS: 0\n"
     ]
    }
   ],
   "source": [
    "for author in authors:\n",
    "    print(\"Number of strings containing 'æ' by {}: {}\".format(author, sum(['æ' in word for word in [t for t in df[df['author']==author].text]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author']==author].text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'process', ',', 'however', ',', 'afforded', 'me', 'no', 'means', 'of']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.word_tokenize(df.text[0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27575"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367.6666666666667"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)/75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', 2762),\n",
       " ('the', 2225),\n",
       " (\"''\", 2207),\n",
       " ('one', 1623),\n",
       " ('upon', 1411),\n",
       " (\"'s\", 1355),\n",
       " ('could', 1330),\n",
       " ('would', 1258),\n",
       " ('it', 947),\n",
       " ('he', 900)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcounts = Counter()\n",
    "for sentence in token_list:\n",
    "    wordcounts.update([t.lower() for t in sentence])\n",
    "wordcounts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7227"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = []\n",
    "for word, count in wordcounts.items():\n",
    "    if 5 < count < 200:\n",
    "        wordlist.append(word)\n",
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanc: 11\n",
      "breadth: 14\n",
      "beginning: 45\n",
      "peer: 12\n",
      "grin: 9\n",
      "artists: 8\n",
      "wondrous: 15\n",
      "imitation: 13\n",
      "merest: 6\n",
      "thousands: 16\n"
     ]
    }
   ],
   "source": [
    "for word in wordlist[90:100]:\n",
    "    print(\"{}: {}\".format(word, wordcounts[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The present peculiar condition of affairs at court, and especially of those intrigues in which D is known to be involved, would render the instant availability of the document its susceptibility of being produced at a moment's notice a point of nearly equal importance with its possession.\"\n",
      "\"And what about the window panes?\" \"They were all gone.\n",
      "\"But could not the cavity be detected by sounding?\"\n",
      "\"Everybody got aout o' the idee o' dyin' excep' in canoe wars with the other islanders, or as sacrifices to the sea gods daown below, or from snake bite or plague or sharp gallopin' ailments or somethin' afore they cud take to the water but simply looked forrad to a kind o' change that wa'n't a bit horrible arter a while.\n",
      "\"That is absolutely needless,\" replied G .\n",
      "\"Keep up the largest branch the one on this side,\" said Legrand.\n",
      "\"But, my dear fellow, you are joking then,\" said I, \"this is a very passable skull indeed, I may say that it is a very excellent skull, according to the vulgar notions about such specimens of physiology and your scarabæus must be the queerest scarabæus in the world if it resembles it.\n",
      "\"I believe, sir, you have forgotten to pay for your brandy and water.\"\n",
      "\"But that Kidd's accumulations were immense, is well known.\n",
      "\"Pierre Moreau, tobacconist, deposes that he has been in the habit of selling small quantities of tobacco and snuff to Madame L'Espanaye for nearly four years.\n",
      "\"Not so,\" said I, \"though I confess that my thoughts are not occupied as pleasantly as yours are.\n"
     ]
    }
   ],
   "source": [
    "bleh = 0\n",
    "for text in df.text:\n",
    "    if not text[0].isupper():\n",
    "        print(text)\n",
    "        bleh += 1\n",
    "    if bleh > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'EAP': 793, 'MWS': 381, 'HPL': 167})\n"
     ]
    }
   ],
   "source": [
    "this = Counter()\n",
    "for n, text in enumerate(df.text):\n",
    "    if not text[0].isupper():\n",
    "        this[df.iloc[n].author] += 1\n",
    "print(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_word_frequencies(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            w, e, h, m = line.replace(\"\\\"\", \"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\").split(\",\")[1:]\n",
    "            data.append([w, float(e), float(h), float(m)])\n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'line' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-27029df0ec68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"]\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'line' is not defined"
     ]
    }
   ],
   "source": [
    "line.replace(\"\\\"\", \"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\").split(\",\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = \"3,afforded,\\\"[4.5339866284683176e-05, 1.017405086465508e-05, 4.7641757670422327e-05]\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['word', 'EAP_frequency', 'HPL_frequency', 'MWS_frequency']\n",
    "data = load_word_frequencies('lexicon_frequencies.csv')\n",
    "df_word_frequency = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>EAP_frequency</th>\n",
       "      <th>HPL_frequency</th>\n",
       "      <th>MWS_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>however</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afforded</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>means</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ascertaining</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dimensions</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dungeon</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>might</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>make</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>circuit</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>return</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>point</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>whence</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>set</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>without</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aware</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fact</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>perfectly</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>uniform</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>seemed</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>wall</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  EAP_frequency  HPL_frequency  MWS_frequency\n",
       "0           This       0.000640       0.000519       0.000715\n",
       "1        process       0.000024       0.000026       0.000025\n",
       "2        however       0.000477       0.000213       0.000470\n",
       "3       afforded       0.000045       0.000010       0.000048\n",
       "4          means       0.000270       0.000151       0.000275\n",
       "5   ascertaining       0.000005       0.000001       0.000005\n",
       "6     dimensions       0.000011       0.000004       0.000015\n",
       "7        dungeon       0.000011       0.000004       0.000012\n",
       "8          might       0.000818       0.000706       0.000810\n",
       "9           make       0.000600       0.000663       0.000592\n",
       "10       circuit       0.000010       0.000006       0.000009\n",
       "11        return       0.000244       0.000153       0.000241\n",
       "12         point       0.000182       0.000196       0.000179\n",
       "13        whence       0.000053       0.000020       0.000069\n",
       "14           set       0.000288       0.000303       0.000296\n",
       "15       without       0.000770       0.000578       0.000801\n",
       "16         aware       0.000069       0.000065       0.000055\n",
       "17          fact       0.000147       0.000244       0.000116\n",
       "18     perfectly       0.000078       0.000074       0.000070\n",
       "19       uniform       0.000017       0.000024       0.000017\n",
       "20        seemed       0.000352       0.000546       0.000332\n",
       "21          wall       0.000085       0.000118       0.000086"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this = pd.read_csv('lexicon_frequencies.csv')\n",
    "this.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random = df.iloc[4898]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentence_probability(sentence):\n",
    "    a, b, c = 0, 0, 0\n",
    "    for word in tokenize.word_tokenize(sentence):\n",
    "        if word.lower() in list(df_word_frequency.word):\n",
    "            log_probs = [math.log(v) for v in df_word_frequency.loc[word.lower()][1:]]\n",
    "            a += log_probs[0]\n",
    "            b += log_probs[1]\n",
    "            c += log_probs[2] \n",
    "    return (a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_word_frequency.index = df_word_frequency.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = [v for v in df_word_frequency.loc['process']][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.317976641313019, 0.34895560935665504, 0.33306774933032596]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[probs[i]/sum(probs) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7703 19579\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(df.shape[0]):\n",
    "    line = df.iloc[i]\n",
    "    p = get_sentence_probability(line.text)\n",
    "    if (np.argmax(p) == 0 and line.author == 'EAP') or (np.argmax(p) == 1 and line.author == 'HPL') or (np.argmax(p) == 2 and line.author == 'MWS'):\n",
    "        counter += 1\n",
    "print(counter, df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    probs = get_sentence_probability(sentence)\n",
    "    print(probs, np.argmin(probs), authors[np.argmin(probs)])\n",
    "    return authors[np.argmin(probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_with_probs(sentence):\n",
    "    probs = get_sentence_probability(sentence)\n",
    "    if sum(probs) == 0:\n",
    "        return None\n",
    "    probs = [probs[i]/sum(probs) for i in range(3)]\n",
    "    return (authors[np.argmin(probs)], probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def s(i):\n",
    "    r = df.iloc[i]\n",
    "    print(predict_with_probs(r.text), r.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (spacy)",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
